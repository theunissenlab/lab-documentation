{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Validation\n",
    "***\n",
    "\n",
    "### <font color=black> 1. Convolution Theorem </font>\n",
    "The convolution of a time series $x(t)$ with a filter $h(t)$ to yield $y(t)$ is given by:\n",
    "\n",
    "$$\n",
    "y(t)=x*h=\\int_0^Tx(t-\\tau)h(\\tau)d\\tau\n",
    "$$\n",
    "\n",
    "Here $h$ is causal and finite (up to time $T$). In discrete form this operation is written as:\n",
    "\n",
    "$$\n",
    "y(i)=\\sum_{j=1}^Nx(i-j)h(j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Matlab convolution is done using the command *conv* or *filter*. Both *conv* and *filter* use the same time-domain algorithm but *filter* is a more general function since it can also be used for IIR filtering (infinite impulse response). IIR filters have both a feedforward (a convolution) and a feedback term.\n",
    "\n",
    "The convolution theorem states that the Fourier Transform (FT) of a convolution is the product of the Fourier Transform of each component in the operation ($x$ and $h$ in this case):\n",
    "\n",
    "$$\n",
    "FT[y]=FT[x*h]=FT[x]\\cdot FT[h]\n",
    "$$\n",
    "\n",
    "$$\n",
    "Y(f)=X(f)\\cdot H(f)\n",
    "$$\n",
    "\n",
    "Where we use $H(f)$ to denote the Fourier Transform of $h(t)$. Note that the Fourier Transform of $x$, $h$ and of their convolution $y$ are all complex numbers.\n",
    "\n",
    "The convolution theorem does not play a role in our signal to noise analysis but it is useful to present it here to compare it and contrast it to the correlation theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The Correlation Theorem\n",
    "\n",
    "The correlation between two time series $x(t)$ and $y(t)$ is defined as the average of the cross product of $x$ and $y$ for different delays $\\tau$:\n",
    "\n",
    "$$\n",
    "C_{xy}(\\tau)=\\frac{1}{T}\\int_0^T x^*(t)y(t+\\tau)dt\n",
    "$$\n",
    "\n",
    "Here we are averaging over the entire duration of the signals $x$ and $y$: $T$. If the signal length is infinite, the correlation can be written mathematically as:\n",
    "\n",
    "$$\n",
    "C_{xy}(\\tau)=\\lim_{T \\to \\infty}\\frac{1}{T}\\int_0^T x^*(t)y(t+\\tau)dt\n",
    "$$\n",
    "\n",
    "In discrete form the correlation is written as:\n",
    "\n",
    "$$\n",
    "C_{xy}(k)=\\frac{1}{N-k}\\sum_{i-1}^{N-k} x^*(i)y(i+k)\n",
    "$$\n",
    "\n",
    "Here $k$ is the delay and $N$ is the length of the time series $x$ and $y$ in sample points. Note that cross-correlation is sometimes written with $R$ instead of $C$ (and $C$ reserved for cross-covariance). Note that the order of the indices $xy$ is important. As written, a positive delay, $\\tau$ or $k$, corresponds to $y$ coming after $x$. <span style='background :yellow' > The Matlab function for correlation is *xcorr* (and *xcov* for cross-covariance). Note that in *xcorr* the convetion is reverse for the order of $x$ and $y$. Also the default for *xcorr* is to perform a cross-correlation without normalization (without <span style='background: pink'> dividing </span> by $N-k$). This default is mostly useless and you will want to specify 'unbiased' as an option. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation theorem says that:\n",
    "\n",
    "$$\n",
    "S_{xy}=FT[C_{xy}]=\\langle X^*(f)Y(f)\\rangle\n",
    "$$\n",
    "\n",
    "$S_{xy}$ is called the cross-spectral density. The $\\langle \\rangle $ stand for the expectation value (or average). This average is obtained by dividing the data into segments. The optimal length of the segment depends both on the correlation time of the system (the memory of the system) and on the amount of data that you have since you will want to average over a minimum number of segments to obtain good estimates.\n",
    "\n",
    "When $x=y$, the cross-correlation function becomes the auto-correlation function and the cross-spectral density becomes the power-spectral-density.\n",
    "\n",
    "$$\n",
    "S_{xx}=FT[C_{xx}]=\\langle X^*(f)X(f)\\rangle =\\langle |X(f)|^2\\rangle\n",
    "$$\n",
    "\n",
    "<span style='background:yellow'>Add notes on where to find this code in our python toolboxes. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Signal and Noise\n",
    "\n",
    "If the noise is additive, the noise corrupted reponse, $R$, can be written as a sum of signal, $S$, and noise, $N$:\n",
    "\n",
    "$$\n",
    "R(t)=S(t)+N(t)\n",
    "$$\n",
    "\n",
    "By averaging responses obtained to the same stimulus, one can obtain an estimate of the underlying signal:\n",
    "\n",
    "$$\n",
    "\\bar{R}(t)\\cong S(t)\n",
    "$$\n",
    "\n",
    "In single unit recordings $\\bar{R}$ is the PSTH, in BOLD or ECOG $\\bar{R}$ is the average response (*repeats.mean(0)* in Gallant Code).\n",
    "\n",
    "The noise can then be estimated by subtraction:\n",
    "\n",
    "$$\n",
    "R(t)-\\overline{R(t)}\\cong N(t)\n",
    "$$\n",
    "\n",
    "The signal to noise ratio as a function of frequency can be obtained by calculating the power-spectral densities of $S$ and $R$:\n",
    "\n",
    "$$\n",
    "SNR(f)=\\frac{\\langle \\parallel S(f)\\parallel^2 \\rangle}{\\langle \\parallel N(f)\\parallel^2 \\rangle}\n",
    "$$\n",
    "\n",
    "To obtain a single quantifier for the overall signal to noise ratio, one can calculate the channel capacity also called the information upper bound (in bits/s):\n",
    "\n",
    "$$\n",
    "I=\\int_0^\\infty \\log_2 \\left( 1+\\frac{\\langle S^2 \\rangle}{\\langle N^2 \\rangle}\\right) df\n",
    "$$\n",
    "\n",
    "where we have dropped the frequency for simplicity. The channel capacity gives the maximum information that could be transfered to this channel given that the signal and noise have Gaussian distributions. If the signal is not Gaussian, the actual maximum information that can be transmitted will be smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, one can estimate the overall signal power or noise by summing or averaging across time points. For example,\n",
    "\n",
    "$$\n",
    "N_{tot}=\\sum_t N(t)^2\n",
    "$$\n",
    "\n",
    "Parseval's theorem tells us that summing in time is equivalent to summing in frequency. Therefore:\n",
    "\n",
    "$$\n",
    "N_{tot}=\\sum_f \\parallel N(f) \\parallel ^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following sections, I will use the notation $|N|^2$ and $|S|^2$ to designate noise power or signal power either at a particular frequency, or overall, meaning averaging (or summing but using the same number of points) in time or in frequency. The equations are identical. Similarly, the equations for the coherence at a particular frequency are also valid for the square of the correlation coefficient. In the time domain, quantities like $|N|^2$ and $|S|^2$ are just the variance of the Noise and the variance of the Signal. For zero mean signals the variance and the mean power (per sample point) are identical. If the frequency domain $|N|^2$ and $|S|^2$ are the power spectral densities - these are also averages of squares (like the variance) but estimated for each frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The coherency and the coherence\n",
    "\n",
    "The coherence is used to normalize the cross-spectrum of two time series. The coherency is the cross-spectrum normalized by the square root of the psd. The coherency is the equivalent of the correlation coefficient for time series $(r)$. The coherency is a function of frequency and is a complex number. Its inverse Fourier Transform can be taken to obtain a normalized cross-correlation function in the time domain. The coherency is:\n",
    "\n",
    "$$\n",
    "\\gamma_{x,y}=\\frac{S_{xy}}{\\sqrt{S_{xx}S_{yy}}}\n",
    "$$\n",
    "\n",
    "The coherence is the absolute value square of the coherency. The coherence is therefore a real function (of frequency) bounded between $0$ and $1$. The coherence can be thought of as the square of the Pearson correlation coefficient, $r^2$, for time series.\n",
    "\n",
    "$$\n",
    "\\gamma^2=\\frac{|S_{xy}|^2}{S_{xx}S_{yy}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. The coherence and SNR\n",
    "\n",
    "The coherence between a single trial reponse $(R=S+N)$ and the signal $(S)$ is function of signal to noise. Using the fact that the noise is uncorrelated to the signal, it can easily be shown that:\n",
    "\n",
    "$$\n",
    "\\gamma_{R,S}^2=\\frac{\\langle S^2 \\rangle}{\\langle S^2\\rangle + \\langle N^2\\rangle}\n",
    "$$\n",
    "\n",
    "Equivalently:\n",
    "\n",
    "$$\n",
    "\\frac{\\langle S^2 \\rangle}{\\langle N^2\\rangle}=\\frac{\\gamma^2}{1-\\gamma^2}\n",
    "$$\n",
    "\n",
    "The information capacity can therefore be rewritten as:\n",
    "\n",
    "$$\n",
    "I_{Capacity}=\\int_0^\\infty -\\log_2 \\left(1-\\gamma_{R,S}^2 \\right)df\n",
    "$$\n",
    "\n",
    "More generally, the coherence measures the degree of the linear relationship between two time-series. If time series $y$, can be obtained by convolving time series $x$ with a filter and adding Gaussian noise the *actual* mutual information between $x$ and $y$ is also given by:\n",
    "\n",
    "$$\n",
    "I_{Linear}=\\int_0^\\infty -\\log_2 \\left(1-\\gamma_{x,y}^2 \\right)df\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Bias-free estimations of signal and noise\n",
    "\n",
    "We noted that $\\overline{R}\\cong S$ and $N_{est}=R-\\overline{R}\\cong N$. If we are using this averaging technique to estimate the signal and noise, do we obtain a bias-free estimate of the SNR? To answer this question we can calcualte the power-spectral densities of our estimates of signal and noise and assess whether we are under or over estimating these quantities. In the following section, I have stopped using $\\langle \\rangle$ to show averaging but all quantities shown are expectation values. $M$ is the number of trials (repetitions) used to estimate the mean response. The noise across trials is uncorrelated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The power of the average response is then:\n",
    "\n",
    "$$\n",
    "|\\bar{R}|^2=|S|^2+\\frac{|N|^2}{M}\n",
    "$$\n",
    "\n",
    "We are therefore overestimating signal power by $\\frac{|N|^2}{M}$.\n",
    "\n",
    "The power of our noise estimate is:\n",
    "\n",
    "$$\n",
    "|N_{est}|^2=|S-S|^2+ \\bigg|N\\bigg(1-\\frac{1}{M} \\bigg) \\bigg|^2 + \\frac{M-1}{M^2}|N|^2\n",
    "$$\n",
    "\n",
    "The $|N(1-\\frac{1}{M})|^2$ term comes from the noise in the average that is the same than the noise in the trial. The $\\frac{M-1}{M^2}|N|^2$ term comes from the $M-1$ noise in the average that are uncorrelated with each other and with the noise in the current trial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "|N_{est}|^2=|N|^2 \\bigg[ \\bigg(1-\\frac{1}{M} \\bigg)^2 + \\frac{M-1}{M^2} \\bigg]\n",
    "$$\n",
    "\n",
    "$$\n",
    "|N_{est}|^2=|N|^2 \\bigg[\\frac{M-1}{M} \\bigg]\n",
    "$$\n",
    "\n",
    "We are therefore under estimating the noise by $\\frac{M-1}{M}$. To obtain bias-free estimates of the SNR one could therefore correct the estimate by the factor $\\frac{M}{(M-1)}$ and then use the bias-free noise estimate to correct the signal estimate by removing $\\frac{|N|^2}{M}$. In Hsu, Borst and Theunissen (2004), we show how to obtain bias-free estimates of these signal to noise ratio using the coherence function. Our approach uses the same algebra as in this derivation but it also allows one to obtain bias-free estimates of model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. The explainable variance as defined in the Gallant Lab\n",
    "\n",
    "The Gallant Lab code uses the term residual for our noise. $Res(t)\\cong N(t)$. $Res(t)$ is obtained by subtracting the mean response from single responses (called repeats). The variance of $Res(t)$ is therefore the biased noise power:\n",
    "\n",
    "$$\n",
    "|Res(t)|^2=|N|^2\\bigg(\\frac{M-1}{M}\\bigg)\n",
    "$$\n",
    "\n",
    "Because the overall responses $(S(t)+N(t))$ are $z$-scored is the code (or at least should be):\n",
    "\n",
    "$$\n",
    "|S|^2+|N|^2=1\n",
    "$$\n",
    "\n",
    "The uncorrected explainable variance $(ev)$ is given by:\n",
    "\n",
    "$$\n",
    "ev=1-|Res(t)|^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "ev=|S|^2+|N|^2-|N|^2\\frac{M-1}{M}\n",
    "$$\n",
    "\n",
    "$$\n",
    "ev=|S|^2+\\frac{|N|^2}{M}\n",
    "$$\n",
    "\n",
    "Notice that:\n",
    "\n",
    "$$\n",
    "1-ev=|Res(t)|^2=|N|^2\\bigg(\\frac{M-1}{M}\\bigg)\n",
    "$$\n",
    "\n",
    "Thus, to obtain the unbiased signal power (or signal variance), one can calculate a corrected explainable variance, $ev_c$:\n",
    "\n",
    "$$\n",
    "ev_c=ev-\\frac{1-ev}{M-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "ev_c=|S|^2+\\frac{|N|^2}{M}-|N|^2\\bigg(\\frac{M-1}{M}\\bigg)\\bigg(\\frac{1}{M-1}\\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "ev_c=|S|^2\n",
    "$$\n",
    "\n",
    "The explainable variance is therefore equal to the signal power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In model validation, one can use the coefficient of determination, $R^2$. If $P$ is the prediction, and $S+N$, like above, is the response of one trial (repeat), then:\n",
    "\n",
    "$$\n",
    "R^2=1-\\frac{|(S+N)-P|^2}{|S+N|^2}=1-\\frac{|S-P|^2+|N|^2}{|S|^2+|N|^2}\n",
    "$$\n",
    "\n",
    "The ceiling value of $R^2$ is when $P=S$:\n",
    "\n",
    "$$\n",
    "R_{ceil}^2=1-\\frac{|S-S|^2+|N|^2}{|S|^2+|N|^2}=1-\\frac{|N|^2}{|S|^2+|N|^2}\n",
    "$$\n",
    "\n",
    "Since we $z$-scored the data, $|S|^2+|N|^2=1$ and $|N|^2=1-|S|^2$. Therefore,\n",
    "\n",
    "$$\n",
    "R_{ceil}^2=1-(1-|S|^2)=|S|^2=ev_c\n",
    "$$\n",
    "\n",
    "The corrected value is given by:\n",
    "\n",
    "$$\n",
    "\\frac{R^2}{R_{ceil}^2}=\\frac{1-|(S+N)-P|^2}{ev_c}\n",
    "$$\n",
    "\n",
    "Note that, in the denominator, you are comparing your prediction to a signal trial or repeat $(S+N)$ and NOT to the average response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Estimating SNR directly from coherence or correlation coefficients\n",
    "\n",
    "The unbiased estimates of signal power and noise power described above can be used to calculate the coherence and for model validation compare the predicted signal power to the actual signal power. These calculations can also performed by splitting the data into two halves as shown in Hsu, Borst and Theunissen (2004). More specifically the coherence between signal+noise and signal can be obtained with:\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\gamma_{S,S+N}^2}-1=\\frac{M}{2}\\bigg(-1+\\sqrt{\\frac{1}{\\gamma_{\\frac{M}{2}}^2}}\\bigg) \\tag1\n",
    "$$\n",
    "\n",
    "Where $\\gamma_{\\frac{M}{2}}^2$ is the coherence obtained between half of the trials (or repeats) and the other half. When one has 2 trials:\n",
    "\n",
    "$$\n",
    "\\gamma_{S,S+N}^2=\\sqrt{\\gamma_{\\frac{M}{2}}^2}\n",
    "$$\n",
    "\n",
    "Similarly, when comparing to the prediction of the model, $P$, we find:\n",
    "\n",
    "$$\n",
    "\\frac{\\gamma_{P,S+N}^2}{\\gamma_{P,\\bar{R}}^2}=\\frac{\\gamma_{S,S+N}^2}{\\gamma_{S,\\bar{R}}^2}=\\frac{1+\\sqrt{\\frac{1}{\\gamma_{\\frac{M}{2}}^2}}}{M\\bigg(-1+\\sqrt{\\frac{1}{\\gamma_{\\frac{M}{2}}^2}} \\bigg)+2} \\tag2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In model validation, we are interested in comparing $\\gamma_{P,S+N}^2$ to the ceiling value $\\gamma_{S,S+N}^2$ or :\n",
    "\n",
    "$$\n",
    "\\frac{\\gamma_{P,S+N}^2}{\\gamma_{S,S+N}^2}=\\frac{\\gamma_{P,\\bar{R}}^2}{2}\\bigg(1+\\sqrt{\\frac{1}{\\gamma_{\\frac{M}{2}}^2}} \\bigg)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These same equations apply to correlation coefficients squared but for that purpose the approach in section 7 is more straightforward (<span style='background:pink'>I still need to do the algebra to show that it is identical </span>). Note that this equation will give $0/0$ when you are in frequencies where the coherence is very small. I recommend calculating the numerator with equation 2 and the denominator with equation 1 and plotting these as a function of frequency. The ratio can then be taken when both coherences significantly above $0$. The numerator should always be smaller than the denominator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. The Jackknife resampling technique\n",
    "\n",
    "The Jackknife is a statistical technique that enables one to generate bias-free estimates of power, coherence, etc by extrapolating the results to infinite data size. Moreover, as for other resampling techniques, the Jackknife gives you an estimate of the error in your estimate. if $\\theta$ is the estimate of our parameter (e.g. coherence) for all the data of size $n=N$ and $\\theta_{\\hat{i}}$ is the estimate obtained after deleting the $i^{th}$ trial, then one can obtain a pseudo-value $p_i$ given by a $1/n$ estrapolation to infinite data size. <img src=\"files/Jackknife.png\" width=500>\n",
    "\n",
    "The pseudo-value can be shown to be:\n",
    "\n",
    "$$\n",
    "p_i=N\\theta-(N-1)\\theta_{\\hat{i}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average value of the pseudo-values yields the bias-corrected estimator and the standard error of this mean yields an estimate of the standard error of your measurement. When the Jackknife is used for coherence correction and error estimation, it is often done after transformation. Thomson and Chave recommend using the inverse hyperbolic tangent.\n",
    "\n",
    "<span style='background:pink'>The coherence estimator (*compute_coherence_mean*) in the tutorial (and in *strflab*) calculates the coherence using multi-taper methods that are bias corrected using the Jackknife after data transformation. </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
